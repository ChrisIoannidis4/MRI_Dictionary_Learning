{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_parameters import *\n",
    "from InitializeDict_M_Coeff import *\n",
    "from optimization_problems import * \n",
    "from transfer_classifiers import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_paths=get_lists_of_of_paths(path_to_images)\n",
    "\n",
    "# roi_masks=[]\n",
    "# segm_masks=[]\n",
    "# for j in range(len(masks_paths)):\n",
    "#     mid_file=get_lists_of_of_paths(masks_paths[j])\n",
    "#     roi_masks.append(np.load(mid_file[3]))\n",
    "\n",
    "#     segm_mask = sitk.ReadImage(mid_file[1], sitk.sitkFloat32)\n",
    "#     segm_masks.append(sitk.GetArrayFromImage(segm_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in get_lists_of_of_paths('./subjects'):\n",
    "#     image = sitk.ReadImage(path)\n",
    "#     image_array = (sitk.GetArrayFromImage(image)).reshape(384,384)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mri_files=get_lists_of_of_paths('./subjects')\n",
    "\n",
    "# print(mri_files)\n",
    "# image_paths=[]\n",
    "# mri_images=[]\n",
    "# for j in range(44,100): #len(mri_files)):\n",
    "#     mid_file=get_lists_of_of_paths(mri_files[j])\n",
    "#     image_paths.append(get_lists_of_of_paths(mid_file[0]))\n",
    "#     for i in range(160):   \n",
    "#         image = sitk.ReadImage(image_paths[j][0])\n",
    "#         image_array = (sitk.GetArrayFromImage(image)).reshape(384,384)\n",
    "#         name = \"./MRI_Arrays/\" + mri_files[j][-7:] + \".npy\" \n",
    "#         np.save(name, image_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_paths=get_lists_of_of_paths(\"./masks\")\n",
    "# for j in range(len(masks_paths)):\n",
    "#     mid_file=get_lists_of_of_paths(masks_paths[j])\n",
    "#     roi_mask = np.load(mid_file[3])\n",
    "#     name = \"./roi_masks_dataset/roi_\" + masks_paths[j][-7:] + \".npy\" \n",
    "#     np.save(name, roi_mask)\n",
    "\n",
    "\n",
    "#     segm_mask = sitk.ReadImage(mid_file[1], sitk.sitkFloat32)\n",
    "#     segm_mask_1 = sitk.GetArrayFromImage(segm_mask)\n",
    "#     name = \"./segm_masks_dataset/segm_\" + masks_paths[j][-7:] + \".npy\" \n",
    "#     np.save(name, segm_mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeshiftSIFT(array3d, x_coordinate, y_coordinate, z_coordinate ):\n",
    "\n",
    "    XYaxis=array3d[:,:,z_coordinate].astype('uint8')\n",
    "    XZaxis=array3d[:,y_coordinate,:].astype('uint8')\n",
    "    YZaxis=array3d[x_coordinate,:,:].astype('uint8')\n",
    "    # gray = cv2.cvtColor(XYaxis, cv2.COLOR_BGR2GRAY)\n",
    "    keypoint1= cv2.KeyPoint(x_coordinate, y_coordinate, 1)\n",
    "    _, descriptor1 = sift.compute(XYaxis, [keypoint1] )\n",
    "\n",
    "\n",
    "    # gray = cv2.cvtColor(XZaxis, cv2.COLOR_BGR2GRAY)\n",
    "    keypoint2= cv2.KeyPoint(x_coordinate, z_coordinate, 1)\n",
    "    _, descriptor2 = sift.compute(XZaxis,[keypoint2])\n",
    "\n",
    "    # gray = cv2.cvtColor(XZaxis, cv2.COLOR_BGR2GRAY)\n",
    "    keypoint3= cv2.KeyPoint(y_coordinate, z_coordinate, 1)\n",
    "    _, descriptor3 = sift.compute(XZaxis,[keypoint3])\n",
    "\n",
    "\n",
    "    descriptor = descriptor1 + descriptor2 + descriptor3 \n",
    "    descriptor = descriptor / 3\n",
    "\n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_descriptors1(image, segmetation_mask, name):\n",
    "\n",
    "    FBlistofCoordinates=[]\n",
    "    FAClistofCoordinates=[]\n",
    "    TBlistofCoordinates=[]\n",
    "    TAClistofCoordinates=[]\n",
    "    image=image\n",
    "    name=name\n",
    "    # for y in range(150,275,3):\n",
    "    #     for x in range(70,250,3):\n",
    "    #         for z in range(30,120,3):\n",
    "    #             if (segmetation_mask1[x,y,z]==1\n",
    "    #                 and segmetation_mask2[x,y,z]!=0\n",
    "    #                 and segmetation_mask3[x,y,z]!=0\n",
    "    #                 and segmetation_mask4[x,y,z]!=1):\n",
    "    #                 FBlistofCoordinates.append([x,y,z])\n",
    "    #             elif (segmetation_mask1[x,y,z]==2\n",
    "    #                 and segmetation_mask2[x,y,z]!=2\n",
    "    #                 and segmetation_mask3[x,y,z]!=2\n",
    "    #                 and segmetation_mask4[x,y,z]!=2):\n",
    "    #                 FAClistofCoordinates.append([x,y,z])\n",
    "    #             elif (segmetation_mask1[x,y,z]==3\n",
    "    #                 and segmetation_mask2[x,y,z]!=3\n",
    "    #                 and segmetation_mask3[x,y,z]!=3\n",
    "    #                 and segmetation_mask4[x,y,z]!=3):\n",
    "    #                 TBlistofCoordinates.append([x,y,z])\n",
    "    #             elif (segmetation_mask1[x,y,z]==4\n",
    "    #                 and segmetation_mask2[x,y,z]!=4\n",
    "    #                 and segmetation_mask3[x,y,z]!=4\n",
    "    #                 and segmetation_mask4[x,y,z]!=4):\n",
    "    #                 TAClistofCoordinates.append([x,y,z])\n",
    "    \n",
    "\n",
    "\n",
    "    ListOfCoordinates=[]\n",
    "\n",
    "    # for i in range(len(TAClistofCoordinates)):\n",
    "    #     ListOfCoordinates.append(TAClistofCoordinates[i])\n",
    "\n",
    "    \n",
    "    # for i in range(len(TBlistofCoordinates)):\n",
    "    #     ListOfCoordinates.append(TBlistofCoordinates[i])\n",
    "\n",
    "    # for i in range(len(FAClistofCoordinates)):\n",
    "    #     ListOfCoordinates.append(FAClistofCoordinates[i])\n",
    "\n",
    "    # for i in range(len(FBlistofCoordinates)):\n",
    "    #     ListOfCoordinates.append(FBlistofCoordinates[i])    \n",
    "\n",
    "    for y in range(150,275,3):\n",
    "        for x in range(70,250,3):\n",
    "            for z in range(30,120,3):\n",
    "                if segmetation_mask[x,y,z]==1:\n",
    "                    FBlistofCoordinates.append([x,y,z])\n",
    "                elif segmetation_mask[x,y,z]==2:\n",
    "                    FAClistofCoordinates.append([x,y,z])\n",
    "                elif segmetation_mask[x,y,z]==3:\n",
    "                    TBlistofCoordinates.append([x,y,z])\n",
    "                elif segmetation_mask[x,y,z]==4:\n",
    "                    TAClistofCoordinates.append([x,y,z])\n",
    "\n",
    "\n",
    "\n",
    "    # (np.array(TAClistofCoordinates),np.array(TBlistofCoordinates),np.array(FAClistofCoordinates),\n",
    "    #                                   np.array(FBlistofCoordinates)), axis=0)\n",
    "\n",
    "\n",
    "    # ListOfCoordinates = np.random.permutation(ListOfCoordinates.shape[0])\n",
    "\n",
    "    for i in (0, 500, 1000, 2000, 7000, 13000):\n",
    "        append_to_coordinates(ListOfCoordinates,TBlistofCoordinates, i) \n",
    "    for i in (0, 120, 240, 350, 480, 600, 710, 820 ,930, 1000):\n",
    "        append_to_coordinates(ListOfCoordinates,TAClistofCoordinates, i)\n",
    "    for i in (0, 120, 300, 500, 750, 900, 1100, 1300, 1400, 1575):\n",
    "        append_to_coordinates(ListOfCoordinates,FAClistofCoordinates, i)\n",
    "    for i in (0, 1500, 2800, 5000, 11000):\n",
    "        append_to_coordinates(ListOfCoordinates,FBlistofCoordinates, i)\n",
    "    \n",
    "\n",
    "    return  ListOfCoordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_images(path_to_images):    \n",
    "#     mri_files=get_lists_of_of_paths(path_to_images)\n",
    "#     image_paths=[]\n",
    "#     mri_images=[]\n",
    "#     j=0\n",
    "#     for j in range(44,len(mri_files)):\n",
    "#         mid_file=get_lists_of_of_paths(mri_files[j])\n",
    "#         image_paths.append(get_lists_of_of_paths(mid_file[0]))\n",
    "#         for i in range(160):\n",
    "#             if i==0:    \n",
    "#                 image = sitk.ReadImage(image_paths[j][0])\n",
    "#                 image_array = (sitk.GetArrayFromImage(image)).reshape(384,384)\n",
    "#             else:  \n",
    "#                 image = sitk.ReadImage(image_paths[j][i])\n",
    "#                 image_staging= sitk.GetArrayFromImage(image).reshape(384,384)\n",
    "#                 image_array=np.dstack((image_array,image_staging))\n",
    "#         name = \"MRI_Dataset/\" + mri_files[j][-7 :] + \".npy\"\n",
    "#         np.save(name,image_array)\n",
    "        \n",
    "#     # return image_array\n",
    "#         # mri_images.append(image_array)\n",
    "\n",
    "\n",
    "\n",
    "# get_images(\"./subjects\")\n",
    "\n",
    "# print(\"shape: \" , str(np.load(\"MRI_Dataset/9002817.npy\").shape)) , \"\\nUnique: \" , str(np.unique(np.load(\"MRI_Dataset/9002817.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(3, 43):\n",
    "image=(get_lists_of_of_paths(\"./MRI_Dataset\")[0])\n",
    "name_cache = image[-11:-4]\n",
    "image_test = np.load(image)\n",
    "mask1 = np.load(\"./segm_masks_dataset/segm_\"+name_cache+\".npy\")\n",
    "\n",
    "\n",
    "Coordinates =compute_descriptors1(image_test,mask1, name_cache )\n",
    "# print(len(Coordinates))\n",
    "np.save(\"Sampled_Coordinates.npy\", Coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "image_descriptor=[]\n",
    "Coordinates_file=np.load(\"./Sampled_Coordinates.npy\")\n",
    "Coordinates_file=Coordinates_file.tolist()\n",
    "for coordinate in Coordinates_file:\n",
    "    local_descriptor = makeshiftSIFT(image_test, coordinate[0], coordinate[1], coordinate[2])\n",
    "    temp_name= \"./local_descriptors/image_descriptor_\" + name_cache + \"_\" + str(k)\n",
    "    np.save(temp_name, local_descriptor)\n",
    "    k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coordinates=np.load(\"Sampled_Coordinates.npy\")\n",
    "Coordinates=Coordinates.tolist()\n",
    "for coordinate in Coordinates:\n",
    "    print(coordinate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_descriptors_B(image, segmetation_mask, name):\n",
    "    k=0\n",
    "    for coordinate in Coordinates:\n",
    "        local_descriptor = makeshiftSIFT(image, coordinate[0], coordinate[1], coordinate[2])\n",
    "        temp_name= \"./local_descriptors/image_descriptor_\" + name + \"_\" + str(k)\n",
    "        np.save(temp_name, local_descriptor)\n",
    "        k+=1\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,100):\n",
    "    image=(get_lists_of_of_paths(\"./MRI_Dataset\")[i])\n",
    "    name_cache = image[-11:-4]\n",
    "    print(name_cache)\n",
    "    image_test = np.load(image)\n",
    "    mask = np.load(\"./segm_masks_dataset/segm_\"+name_cache+\".npy\")\n",
    "    # Coordinates = compute_descriptors(image_test,mask, name_cache )\n",
    "    compute_descriptors_B(image_test, mask, name_cache)\n",
    "\n",
    "\n",
    "#     9001104\n",
    "# 9002430\n",
    "# 9002817\n",
    "# 9004175\n",
    "# 9005132\n",
    "# 9006723\n",
    "# 9007827\n",
    "# 9011115\n",
    "# 9011420\n",
    "# 9013161\n",
    "# 9013798\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.004444444444445\n"
     ]
    }
   ],
   "source": [
    "print(len(get_lists_of_of_paths(\"./local_descriptors\"))/1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Coordinates)\n",
    "# np.save(\"Sampled_Coordinates.npy\",np.array(Coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70 150  42]\n",
      " [ 70 150  45]\n",
      " [ 70 150  48]\n",
      " ...\n",
      " [166 258  54]\n",
      " [166 258  99]\n",
      " [166 258 102]]\n"
     ]
    }
   ],
   "source": [
    "# print(np.load(\"Sampled_Coordinates.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_specific_SVM(coordinates, descriptors, array_with_labels):\n",
    "\n",
    "    X=descriptors\n",
    "    Y=[array_with_labels[coordinate[0], coordinate[1], coordinate[2]] for coordinate in coordinates]\n",
    "    \n",
    "\n",
    "    x_train=X[0:800]\n",
    "    y_train=Y[0:1400]\n",
    "    y_test=Y[1400:1800]\n",
    "\n",
    "    # defining parameter range\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "                'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                'kernel': ['rbf', 'poly']\n",
    "                } \n",
    "    \n",
    "    grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3, cv=5 )\n",
    "    \n",
    "    # fitting the model for grid search\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    classifier = grid.best_estimator_\n",
    "    classifier.fit(x_train, y_train)\n",
    "    W = classifier.coeff_\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_901104 = image_specific_SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Coordinates=\n",
    "\n",
    "# x\n",
    "# file_pattern = os.path.join(directory, f\"local_descriptors/image_descriptor_{x_value}_*.npy\")\n",
    "def local_descriptors_of_subject(subject_no):\n",
    "\n",
    "    x_train = np.empty((128, 0))\n",
    "    for i in range(0,3100):\n",
    "        path = \"./local_descriptors/image_descriptor_\" + str(subject_no) + \"_\" + str(i) + \".npy\"\n",
    "        cache_loader = np.load(path)\n",
    "        x_train = np.hstack((x_train, cache_loader.reshape(-1,1)))\n",
    "\n",
    "    x_train=np.transpose(x_train)\n",
    "    print(x_train.shape)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 128)\n"
     ]
    }
   ],
   "source": [
    "X= local_descriptors_of_subject(9001104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 3)\n",
      "(3100, 128)\n",
      "(384, 384, 160)\n"
     ]
    }
   ],
   "source": [
    "coordinates = np.load(\"Sampled_Coordinates.npy\")\n",
    "\n",
    "segm_mask=np.load(\"segm_masks_dataset/segm_9001104.npy\")\n",
    "\n",
    "print(coordinates.shape)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "print(segm_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1.0 values: 500\n",
      "Number of 2.0 values: 1000\n",
      "Number of 3.0 values: 600\n",
      "Number of 4.0 values: 1000\n"
     ]
    }
   ],
   "source": [
    "Y=[segm_mask[coordinate[0], coordinate[1], coordinate[2]] for coordinate in coordinates]\n",
    "\n",
    "\n",
    "unique_values, counts = np.unique(Y, return_counts=True)\n",
    "\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Number of {value} values: {count}\")\n",
    "# print(Y[1700])\n",
    "# count_zero = np.count_nonzero(Y == 0.0)\n",
    "# count_one = np.count_nonzero(Y == 1.0)\n",
    "# count_two = np.count_nonzero(Y == 2.0)\n",
    "# count_three = np.count_nonzero(Y == 3.0)\n",
    "# count_four = np.count_nonzero(Y == 4.0)\n",
    "\n",
    "# print(\"Number of 0.0 values:\", count_zero)\n",
    "# print(\"Number of 1.0 values:\", count_one)\n",
    "# print(\"Number of 2.0 values:\", count_two)\n",
    "# print(\"Number of 3.0 values:\", count_three)\n",
    "# print(\"Number of 4.0 values:\", count_four)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array([Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.           7.66666651   6.          11.33333302  21.33333397\n",
      "  59.66666794   5.33333349   2.66666675  21.33333397   8.\n",
      "  18.33333397   9.          22.          21.           8.\n",
      "   4.66666651  64.66666412  57.          15.66666698   1.\n",
      "   0.           1.33333337   4.66666651  20.33333397 105.\n",
      "  52.66666794   1.33333337   0.           0.           0.\n",
      "   5.          41.           0.           6.33333349  15.\n",
      "   5.33333349  44.33333206  52.66666794  40.66666794   8.33333302\n",
      "  15.66666698   4.33333349  13.          12.66666698  38.\n",
      "  45.66666794  47.66666794  31.66666603  86.33333588  27.66666603\n",
      "   9.66666698   2.33333325   0.          10.          43.66666794\n",
      "  56.66666794 131.66667175  55.           7.           0.\n",
      "   0.           0.          10.66666698  79.           4.\n",
      "   0.           0.           5.33333349  43.33333206   9.66666698\n",
      "  65.          54.           1.66666663   0.33333334   1.66666663\n",
      "   5.33333349  43.33333206  27.33333397  81.          51.33333206\n",
      "  59.           2.33333325   1.66666663   1.           0.\n",
      "  17.          79.33333588  86.66666412  63.66666794  18.\n",
      "  10.           0.           0.           3.33333325  31.33333397\n",
      "  85.66666412  19.          26.           0.33333334   2.66666675\n",
      "  38.33333206  23.66666603  14.66666698  45.33333206  11.33333302\n",
      "  22.           0.           1.          10.33333302  36.33333206\n",
      "  56.          54.          24.           7.66666651   0.\n",
      "   4.           3.          18.66666603  59.33333206  68.66666412\n",
      "  41.33333206   8.           2.           0.33333334   1.33333337\n",
      "  20.          25.33333397  36.           3.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# image_specific_SVM\n",
    "# (coordinates, X, Y)\n",
    "data=np.concatenate((X, Y.T), axis=1)\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00239808 0.00240964 ... 0.99624066 0.9967533  1.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "x_train = data[:,:-1]\n",
    "y_train = data[:,-1]\n",
    "for column in range(x_train.shape[1]):\n",
    "    x_train[:,column] = x_train[:,column] / max(x_train[:,column])\n",
    "print(np.unique(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['poly']} \n",
    "\n",
    "\n",
    "# {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "#\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3, cv=5 , scoring='balanced_accuracy')\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(x_train, y_train)\n",
    "classifier = grid.best_estimator_\n",
    "results = classifier.fit(x_train, y_train)\n",
    "print(results)\n",
    "print(grid.best_params_)\n",
    "W = classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "svm1=svm.SVC(C=0.1, gamma=1, kernel = 'poly')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, train_size= 0.9)\n",
    "\n",
    "num_epochs = 100\n",
    "history = []\n",
    "\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "plt.plot(np.arange(num_epochs), history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# svm1.fit(x_train, y_train)\n",
    "# train_pred= svm1.predict(x_train)\n",
    "# print(classification_report(y_train, train_pred))\n",
    "# print('=======================================================')\n",
    "# test_pred= svm1.predict(x_test)\n",
    "# print(classification_report(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.92      0.88       500\n",
      "         2.0       0.84      0.82      0.83      1000\n",
      "         3.0       0.99      0.62      0.77       600\n",
      "         4.0       0.75      0.91      0.82      1000\n",
      "\n",
      "    accuracy                           0.82      3100\n",
      "   macro avg       0.86      0.82      0.82      3100\n",
      "weighted avg       0.84      0.82      0.82      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm1=svm.SVC(C=10, gamma=0.1, kernel = 'poly')\n",
    "svm1.fit(x_train, y_train)\n",
    "y_pred= svm1.predict(x_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[462  22   1  15]\n",
      " [ 29 828   5 138]\n",
      " [  5  43 448 104]\n",
      " [  4  49   3 944]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix#, precision, recall, f1_score, balanced_accuracy\n",
    "y_pred = classifier.predict(x_train)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[257 146  55  42]\n",
    " [106 548  93 253]\n",
    " [ 25 146 232 197]\n",
    " [ 49 245  27 679]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
